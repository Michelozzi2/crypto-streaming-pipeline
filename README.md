# ğŸš€ Crypto Streaming Pipeline

Pipeline de streaming temps rÃ©el pour l'analyse de donnÃ©es de cryptomonnaies avec Apache Kafka, Spark Streaming, et ClickHouse.

## ğŸ“‹ Table des matiÃ¨res

- [Architecture](#architecture)
- [Technologies](#technologies)
- [PrÃ©requis](#prÃ©requis)
- [Installation](#installation)
- [Utilisation](#utilisation)
- [Structure du projet](#structure-du-projet)
- [FonctionnalitÃ©s](#fonctionnalitÃ©s)
- [Monitoring](#monitoring)
- [Tests](#tests)
- [Roadmap](#roadmap)

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  CoinCap    â”‚
â”‚  API        â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Kafka Producer     â”‚  â† Ingestion temps rÃ©el
â”‚  (Python)           â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Apache Kafka       â”‚  â† Message Broker
â”‚  (Topic: crypto)    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚                     â”‚
       â–¼                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PostgreSQL  â”‚    â”‚  Spark Streamingâ”‚
â”‚  (Raw Data)  â”‚    â”‚  (Transformations)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  ClickHouse     â”‚
                    â”‚  (Time-Series)  â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  Grafana        â”‚
                    â”‚  (Dashboards)   â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ› ï¸ Technologies

- **Apache Kafka** : Message broker pour streaming
- **Apache Spark Streaming** : Traitement distribuÃ© en temps rÃ©el
- **PostgreSQL** : Base de donnÃ©es relationnelle pour donnÃ©es brutes
- **ClickHouse** : Base de donnÃ©es columnar pour time-series
- **Redis** : Cache in-memory
- **Grafana** : Visualisation et dashboards
- **Prometheus** : Monitoring et mÃ©triques
- **Docker** : Containerisation

## ğŸ“¦ PrÃ©requis

- Docker Desktop (ou Docker Engine + Docker Compose)
- Python 3.9+
- Au moins 8 GB de RAM disponible
- 10 GB d'espace disque

## ğŸš€ Installation

### 1. Cloner le repository

```bash
git clone <votre-repo>
cd crypto-streaming-pipeline
```

### 2. CrÃ©er l'environnement Python

```bash
python -m venv venv
source venv/bin/activate  # Sur Windows: venv\Scripts\activate
pip install -r requirements.txt
```

### 3. DÃ©marrer les services Docker

```bash
docker-compose up -d
```

**VÃ©rifier que tous les services sont lancÃ©s :**

```bash
docker-compose ps
```

Vous devriez voir tous les services avec le statut "Up".

### 4. VÃ©rifier les connexions

**Kafka UI** : http://localhost:8080  
**Grafana** : http://localhost:3000 (admin/admin)  
**Prometheus** : http://localhost:9090  
**ClickHouse** : http://localhost:8123  

## ğŸ¯ Utilisation

### DÃ©marrer le Producer (collecte de donnÃ©es)

```bash
python producer/kafka_producer.py
```

### DÃ©marrer le Consumer (stockage PostgreSQL)

```bash
python consumer/kafka_consumer.py
```

### DÃ©marrer Spark Streaming (transformations)

```bash
spark-submit --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0 \
  spark/streaming_job.py
```

### ArrÃªter le pipeline

```bash
docker-compose down
```

Pour supprimer aussi les volumes (donnÃ©es) :

```bash
docker-compose down -v
```

## ğŸ“ Structure du projet

```
crypto-streaming-pipeline/
â”œâ”€â”€ producer/               # Kafka Producer (ingestion API)
â”‚   â”œâ”€â”€ kafka_producer.py
â”‚   â”œâ”€â”€ api_client.py
â”‚   â””â”€â”€ config.py
â”œâ”€â”€ consumer/               # Kafka Consumer (PostgreSQL)
â”‚   â”œâ”€â”€ kafka_consumer.py
â”‚   â””â”€â”€ db_manager.py
â”œâ”€â”€ spark/                  # Spark Streaming jobs
â”‚   â”œâ”€â”€ streaming_job.py
â”‚   â”œâ”€â”€ transformations.py
â”‚   â””â”€â”€ clickhouse_writer.py
â”œâ”€â”€ monitoring/             # Prometheus & Grafana configs
â”‚   â”œâ”€â”€ prometheus.yml
â”‚   â””â”€â”€ grafana/
â”œâ”€â”€ tests/                  # Tests unitaires et d'intÃ©gration
â”œâ”€â”€ docs/                   # Documentation
â”œâ”€â”€ config/                 # Configurations
â”œâ”€â”€ data/                   # DonnÃ©es locales (gitignored)
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env
â””â”€â”€ README.md
```

## âœ¨ FonctionnalitÃ©s

### Phase 1 (Semaine 1) - âœ…
- [x] Setup infrastructure Docker
- [x] Kafka Producer basique
- [x] Consommation et stockage PostgreSQL
- [x] Monitoring basique

### Phase 2 (Semaine 2) - ğŸš§ En cours
- [ ] Spark Streaming avec transformations
- [ ] AgrÃ©gations par fenÃªtre temporelle
- [ ] Moyennes mobiles
- [ ] Stockage ClickHouse

### Phase 3 (Semaine 3) - ğŸ“‹ Ã€ venir
- [ ] DÃ©tection d'anomalies
- [ ] SystÃ¨me d'alertes
- [ ] Dashboards Grafana
- [ ] Tests automatisÃ©s
- [ ] Documentation complÃ¨te

## ğŸ“Š Monitoring

### MÃ©triques collectÃ©es

- **Kafka** : Lag, throughput, nombre de messages
- **Producer** : Taux d'envoi, erreurs, latence
- **Consumer** : Taux de consommation, erreurs
- **Bases de donnÃ©es** : Connexions, requÃªtes, latence

### Dashboards Grafana

1. **Pipeline Overview** : Vue d'ensemble du pipeline
2. **Kafka Metrics** : MÃ©triques Kafka dÃ©taillÃ©es
3. **Crypto Prices** : Prix en temps rÃ©el
4. **Alerts Dashboard** : Alertes et anomalies

## ğŸ§ª Tests

```bash
# Tests unitaires
pytest tests/unit/

# Tests d'intÃ©gration
pytest tests/integration/

# Tous les tests avec couverture
pytest --cov=. tests/
```

## ğŸ“ˆ Roadmap

- **v1.0** : Pipeline de base fonctionnel âœ…
- **v1.1** : Transformations avancÃ©es ğŸš§
- **v1.2** : ML pour prÃ©dictions ğŸ“‹
- **v2.0** : Multi-cloud deployment ğŸ“‹

## ğŸ¤ Contribution

Contributions bienvenues ! Voir [CONTRIBUTING.md](CONTRIBUTING.md)

## ğŸ“ Licence

MIT License

## ğŸ‘¤ Auteur

Data Engineer en formation - Portfolio project

## ğŸ“ Support

Pour toute question : [CrÃ©er une issue](https://github.com/votre-repo/issues)

---

**Note** : Ce projet est Ã  but Ã©ducatif et de dÃ©monstration de compÃ©tences data engineering.
