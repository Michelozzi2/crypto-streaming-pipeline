"""
Producer Kafka pour le pipeline crypto streaming
R√©cup√®re les donn√©es de l'API CoinCap et les envoie dans Kafka
"""
import json
import time
import logging
import signal
import sys
from typing import Optional
from datetime import datetime

from kafka import KafkaProducer
from kafka.errors import KafkaError

# Import de nos modules
import config
from api_client import CoinCapAPIClient

# Configuration du logging
logging.basicConfig(
    level=getattr(logging, config.LOG_LEVEL),
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout),
        logging.FileHandler('producer.log', encoding='utf-8')
    ]
)
# Force UTF-8 pour stdout sur Windows
if sys.stdout.encoding != 'utf-8':
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
logger = logging.getLogger(__name__)


class CryptoKafkaProducer:
    """
    Producer Kafka pour les donn√©es crypto
    """
    
    def __init__(self):
        """Initialise le producer Kafka et le client API"""
        self.running = False
        self.producer: Optional[KafkaProducer] = None
        self.api_client: Optional[CoinCapAPIClient] = None
        
        # Statistiques
        self.messages_sent = 0
        self.errors = 0
        self.start_time = None
        
    def setup(self):
        """Configure le producer Kafka et le client API"""
        try:
            logger.info("üöÄ D√©marrage du Producer Crypto Kafka")
            logger.info("=" * 60)
            
            # 1. Initialiser le client API
            logger.info("üì° Connexion √† l'API CoinCap...")
            self.api_client = CoinCapAPIClient(
                base_url=config.COINCAP_API_URL,
                api_key=config.COINCAP_API_KEY
            )
            
            # 2. Initialiser le producer Kafka
            logger.info("üîå Connexion √† Kafka...")
            self.producer = KafkaProducer(
                bootstrap_servers=config.KAFKA_BOOTSTRAP_SERVERS,
                
                # S√©rialisation en JSON
                value_serializer=lambda v: json.dumps(v).encode('utf-8'),
                key_serializer=lambda k: k.encode('utf-8') if k else None,
                
                # Configuration de performance
                acks='all',  # Attend confirmation de tous les replicas
                retries=3,   # Retry automatique
                max_in_flight_requests_per_connection=5,
                
                # Compression pour √©conomiser la bande passante
                compression_type='gzip',
                
                # Batching pour meilleures performances
                linger_ms=10,
                batch_size=16384
            )
            
            logger.info("‚úÖ Producer Kafka initialis√©")
            logger.info("=" * 60)
            logger.info(f"üìä Configuration:")
            logger.info(f"   ‚Ä¢ Kafka: {config.KAFKA_BOOTSTRAP_SERVERS}")
            logger.info(f"   ‚Ä¢ Topic: {config.KAFKA_TOPIC_RAW}")
            logger.info(f"   ‚Ä¢ Cryptos: {len(config.CRYPTOS_TO_TRACK)}")
            logger.info(f"   ‚Ä¢ Intervalle: {config.DATA_FETCH_INTERVAL}s")
            logger.info("=" * 60)
            
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de l'initialisation: {e}")
            return False
    
    def send_to_kafka(self, data: dict) -> bool:
        """
        Envoie un message √† Kafka
        
        Args:
            data: Donn√©es √† envoyer
            
        Returns:
            True si succ√®s, False sinon
        """
        try:
            # Utiliser le symbol comme cl√© pour le partitioning
            key = data.get('symbol', 'UNKNOWN')
            
            # Envoyer le message
            future = self.producer.send(
                config.KAFKA_TOPIC_RAW,
                key=key,
                value=data
            )
            
            # Attendre la confirmation (avec timeout)
            record_metadata = future.get(timeout=10)
            
            logger.debug(
                f"üì§ Message envoy√©: {key} "
                f"‚Üí partition {record_metadata.partition} "
                f"offset {record_metadata.offset}"
            )
            
            self.messages_sent += 1
            return True
            
        except KafkaError as e:
            logger.error(f"‚ùå Erreur Kafka: {e}")
            self.errors += 1
            return False
        except Exception as e:
            logger.error(f"‚ùå Erreur inattendue: {e}")
            self.errors += 1
            return False
    
    def fetch_and_send(self):
        """
        R√©cup√®re les donn√©es de l'API et les envoie √† Kafka
        """
        try:
            logger.info(f"üìä R√©cup√©ration de {len(config.CRYPTOS_TO_TRACK)} cryptos...")
            
            # R√©cup√©rer les donn√©es
            raw_data = self.api_client.get_multiple_assets(config.CRYPTOS_TO_TRACK)
            
            if not raw_data:
                logger.warning("‚ö†Ô∏è  Aucune donn√©e r√©cup√©r√©e")
                return
            
            # Envoyer chaque crypto √† Kafka
            success_count = 0
            for item in raw_data:
                formatted = self.api_client.format_for_kafka(item)
                if formatted and self.send_to_kafka(formatted):
                    success_count += 1
            
            # Log du r√©sultat
            logger.info(
                f"‚úÖ Envoy√© {success_count}/{len(raw_data)} messages | "
                f"Total: {self.messages_sent} | Erreurs: {self.errors}"
            )
            
        except Exception as e:
            logger.error(f"‚ùå Erreur dans fetch_and_send: {e}")
            self.errors += 1
    
    def run(self):
        """
        Boucle principale du producer
        """
        if not self.setup():
            logger.error("‚ùå √âchec de l'initialisation")
            return
        
        self.running = True
        self.start_time = time.time()
        
        logger.info("üèÉ D√©marrage de la boucle principale")
        logger.info("   Appuie sur Ctrl+C pour arr√™ter\n")
        
        iteration = 0
        
        try:
            while self.running:
                iteration += 1
                logger.info(f"\n{'='*60}")
                logger.info(f"üîÑ It√©ration #{iteration}")
                logger.info(f"{'='*60}")
                
                # R√©cup√©rer et envoyer les donn√©es
                self.fetch_and_send()
                
                # Attendre avant la prochaine it√©ration
                logger.info(f"‚è≥ Pause de {config.DATA_FETCH_INTERVAL}s...\n")
                time.sleep(config.DATA_FETCH_INTERVAL)
                
        except KeyboardInterrupt:
            logger.info("\n\n‚ö†Ô∏è  Interruption clavier d√©tect√©e")
        except Exception as e:
            logger.error(f"‚ùå Erreur fatale: {e}")
        finally:
            self.shutdown()
    
    def shutdown(self):
        """Arr√™t propre du producer"""
        logger.info("\n" + "=" * 60)
        logger.info("üõë Arr√™t du producer...")
        
        self.running = False
        
        # Statistiques finales
        if self.start_time:
            duration = time.time() - self.start_time
            rate = self.messages_sent / duration if duration > 0 else 0
            
            logger.info("üìä Statistiques finales:")
            logger.info(f"   ‚Ä¢ Dur√©e: {duration:.2f}s")
            logger.info(f"   ‚Ä¢ Messages envoy√©s: {self.messages_sent}")
            logger.info(f"   ‚Ä¢ Erreurs: {self.errors}")
            logger.info(f"   ‚Ä¢ Taux: {rate:.2f} msg/s")
        
        # Fermer les connexions
        if self.producer:
            logger.info("üîå Fermeture du producer Kafka...")
            self.producer.flush()
            self.producer.close()
        
        if self.api_client:
            self.api_client.close()
        
        logger.info("‚úÖ Arr√™t termin√©")
        logger.info("=" * 60)


def signal_handler(sig, frame):
    """Gestion des signaux syst√®me (Ctrl+C)"""
    logger.info("\n‚ö†Ô∏è  Signal re√ßu, arr√™t en cours...")
    sys.exit(0)


def main():
    """Point d'entr√©e principal"""
    # G√©rer Ctrl+C proprement
    signal.signal(signal.SIGINT, signal_handler)
    
    # Cr√©er et lancer le producer
    producer = CryptoKafkaProducer()
    producer.run()


if __name__ == "__main__":
    main()
