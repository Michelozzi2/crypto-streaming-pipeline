# üìã Checklist de Progression - Pipeline Crypto Streaming

## Semaine 1 : Fondations (10h)

### Jour 1-2 : Setup Environnement (4h)
- [x] T√©l√©charger et d√©compresser le projet
- [x] Installer Docker Desktop
- [x] Lancer `./start.sh` (Mac/Linux) ou `start.bat` (Windows)
- [x] V√©rifier tous les services : `docker-compose ps`
- [x] Acc√©der √† Kafka UI : http://localhost:8080
- [x] Acc√©der √† Grafana : http://localhost:3000 (admin/admin)
- [x] Acc√©der √† Prometheus : http://localhost:9090
- [x] Cr√©er un environnement virtuel Python
- [x] Installer les d√©pendances : `pip install -r requirements.txt`

**‚úçÔ∏è Notes :**
```
Date de d√©but : 11/11/2025
Probl√®mes rencontr√©s :
Petit probl√®me au lancement de Prometheus

Solutions trouv√©es :
La configuration de stockage/retention ne se met pas dans prometheus.yml. Utiliser les flags de d√©marrage (--storage.tsdb.path et --storage.tsdb.retention.time) dans docker-compose ou le command d‚Äôex√©cution du conteneur.


```

---

### Jour 3-4 : Kafka Producer (4h)
- [ ] Comprendre l'architecture du Producer
- [ ] Cr√©er `producer/config.py`
- [ ] Cr√©er `producer/api_client.py`
- [ ] Cr√©er `producer/kafka_producer.py`
- [ ] Tester la connexion √† l'API CoinCap
- [ ] Tester l'envoi de messages dans Kafka
- [ ] Visualiser les messages dans Kafka UI
- [ ] Ajouter le monitoring Prometheus

**üìù Comp√©tences acquises :**
```
- Connexion √† une API REST : ‚òê Compris ‚òê Appliqu√© ‚òê Ma√Ætris√©
- Kafka Producer basics : ‚òê Compris ‚òê Appliqu√© ‚òê Ma√Ætris√©
- Gestion erreurs/retry : ‚òê Compris ‚òê Appliqu√© ‚òê Ma√Ætris√©
- Monitoring Prometheus : ‚òê Compris ‚òê Appliqu√© ‚òê Ma√Ætris√©
```

---

### Jour 5-7 : Kafka Consumer + PostgreSQL (2h)
- [ ] Cr√©er `consumer/db_manager.py`
- [ ] Cr√©er `consumer/kafka_consumer.py`
- [ ] Tester la consommation depuis Kafka
- [ ] V√©rifier l'insertion dans PostgreSQL
- [ ] Requ√™tes SQL pour voir les donn√©es
- [ ] Ajouter logs et monitoring

---

## Semaine 2 : Transformations (10h)

### Jour 1-2 : Spark Streaming Setup (4h)
- [ ] Installer et configurer Spark
- [ ] Cr√©er `spark/config.py`
- [ ] Premier job Spark : lecture Kafka
- [ ] Test d'affichage dans la console

### Jour 3-4 : Transformations M√©tier (4h)
- [ ] Impl√©menter les fen√™tres temporelles (5min)
- [ ] Calculer les agr√©gations (min, max, avg)
- [ ] Calculer les moyennes mobiles
- [ ] D√©tecter les variations > 5%

### Jour 5-7 : ClickHouse Integration (2h)
- [ ] √âcrire les donn√©es dans ClickHouse
- [ ] V√©rifier les donn√©es
- [ ] Requ√™tes analytiques de test

---

## Semaine 3 : Production & Portfolio (10h)

### Jour 1-2 : Monitoring Avanc√© (3h)
- [ ] Configurer les m√©triques Prometheus
- [ ] Cr√©er des alertes
- [ ] Dashboard Grafana infrastructure

### Jour 3-4 : Dashboard Business (4h)
- [ ] Cr√©er dashboard Grafana crypto
- [ ] Graphiques temps r√©el
- [ ] Visualisations

### Jour 5-7 : Finalisation Portfolio (3h)
- [ ] Tests unitaires (pytest)
- [ ] Documentation technique compl√®te
- [ ] Video d√©mo (2-3 min)
- [ ] Article LinkedIn/Medium
- [ ] Push sur GitHub

---

**Date de d√©but du projet :** ___________
**Date de fin pr√©vue :** ___________

**üéâ Bon courage !**
